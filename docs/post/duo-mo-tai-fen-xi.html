<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark_colorblind" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    <script src='https://blog.meekdai.com/Gmeek/plugins/GmeekVercount.js'></script>
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="# 多模态分析(Multimodal Analysis)


### 一、定义

模态是指事物发生或存在的方式，多模态是指两个或者两个以上模态形式的组合。">
<meta property="og:title" content="多模态分析">
<meta property="og:description" content="# 多模态分析(Multimodal Analysis)


### 一、定义

模态是指事物发生或存在的方式，多模态是指两个或者两个以上模态形式的组合。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://aneverspring.github.io/evenstar//post/duo-mo-tai-fen-xi.html">
<meta property="og:image" content="https://i.afbcs.cn/T4drfF">
<title>多模态分析</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>




<body>
    <div id="header">
<h1 class="postTitle">多模态分析</h1>
<div class="title-right">
    <a href="https://aneverspring.github.io/evenstar/" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/AnEverSpring/evenstar/issues/5" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h1>多模态分析(Multimodal Analysis)</h1>
<h3>一、定义</h3>
<p>模态是指事物发生或存在的方式，多模态是指两个或者两个以上模态形式的组合。换句话说，模态是指某种类型的信息或该信息的表示，当一个研究或者数据集中包含多个模态时，即可称为具有多模态属性的研究或者数据集。人们听到的声音、看到的实物、闻到的味道都是一 种模态，人们生活在一个多种模态相互交融的环境。<sup><a href="#user-content-fn-1-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-1-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></p>
<p>**多模态分析（Multimodal Analysis）**是一种通过整合多种不同类型的数据来源（如图像、文本、音频、视频、传感器数据等）进行信息处理和分析的方法。每种数据来源称为一个“模态”，多模态分析旨在从不同的数据模态中提取和关联有用的信息，从而获得更全面、更准确的分析结果。</p>
<h3>二、背景</h3>
<p>多模态分析的背景源于人类感知和处理信息的多样性。</p>
<p>人类感知世界的方式是多模态的，涉及视觉、听觉、触觉、嗅觉和语言等多种感知通道。日常交流中，人类通过语言、表情、肢体语言和语调共同传达信息，这种多模态信息的结合，使得人类能够更加全面、准确地理解外部世界。随着计算能力和数据获取手段的提高，数据类型越来越多样化，大量多模态数据被不断生成，促使分析方法从单一模态向多模态转变。例如，社交媒体平台上的数据可能包含文本、图像、视频、语音等不同模态的组合；在自动驾驶、智能医疗等领域，传感器产生了多维度的数据流。</p>
<p>在不同应用领域中，单一模态的数据通常难以满足分析需求，各行业越来越重视通过多模态分析获得更深刻的洞察力。</p>
<h3>三、举例</h3>
<h4>3.1 自动驾驶</h4>
<ul>
<li>
<p>摄像头（视觉模态）：摄像头提供车辆周围的高清视觉信息，捕捉车道标记、交通信号、行人、车辆等物体。这些信息对于车道保持、信号灯识别、行人检测等至关重要。然而，摄像头易受光线变化（如黑暗、强光）影响，故需结合其他模态补充。</p>
</li>
<li>
<p>雷达（距离模态）：雷达通过发射电磁波测量物体与车辆之间的距离和速度，能够准确探测远处的物体（如前方车辆），即使在恶劣天气（如大雨、浓雾）下也能保持良好的性能。雷达主要用于车距监控、碰撞预警和紧急刹车辅助。</p>
</li>
<li>
<p>激光雷达（深度模态）：激光雷达通过发射激光束并计算返回时间，生成高精度的3D点云数据，提供车辆周围物体的深度信息。这种深度感知能够识别行人、障碍物和复杂地形。相比普通雷达，激光雷达提供更细致的环境信息。</p>
</li>
<li>
<p>GPS和高清地图：GPS提供车辆的地理位置信息，结合高清地图，帮助车辆规划行驶路径。GPS定位易受环境影响，而多模态融合能够提供更准确的位置信息。</p>
<p>不同模态的传感器各有优缺点，单一模态可能面临环境干扰（如雨雪、强光等）或数据缺失。通过将摄像头的视觉信息、雷达的距离数据和激光雷达的3D点云数据进行融合，自动驾驶系统能够在各种复杂环境中确保感知的准确性与稳定性，提高行车的安全性和决策的可靠性。<sup><a href="#user-content-fn-2-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-2-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup></p>
</li>
</ul>
<h4>3.2 医学影像分析</h4>
<ul>
<li>
<p>CT扫描：CT扫描通过X射线生成身体内部的横截面图像，能够显示骨骼、器官、血管和病变部位的细节。CT扫描特别适合骨折、肿瘤、肺部病变等诊断。</p>
</li>
<li>
<p>磁共振成像：MRI使用强磁场和射频波来生成详细的软组织图像，尤其擅长显示大脑、脊髓、关节等部位的细节。相比CT，MRI对软组织病变的识别更为精准，适合神经系统、肿瘤等疾病的诊断。</p>
</li>
<li>
<p>超声波：超声波利用声波反射生成身体内部图像，广泛用于胎儿发育检查、心脏功能检测以及腹部器官病变分析。</p>
<p>在实际医疗中，单一成像技术往往难以提供全面的诊断信息。例如，CT扫描虽然能提供结构清晰的图像，但难以区分软组织；MRI虽然能够显示软组织的细节，但不适合快速扫描或急诊情况下的应用。通过融合CT、MRI、超声和PET等多种成像模态的数据，医生可以更全面地了解病患的器官结构、病灶形态及功能变化，提高诊断的准确性和治疗决策的精确性。<sup><a href="#user-content-fn-3-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-3-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
</li>
</ul>
<h3>四、对比</h3>
<p>数据来源方面，单模态分析只使用来自一个数据源或一种感知方式的数据进行分析，但容易受到模态本身的局限性影响，例如纯文本分析无法获取语音的情感语气等信息。多模态分析综合多个数据源，如视觉、语音、文本、传感器等，融合不同模态的数据进行更全面的分析，数据多样化使得多模态分析能够从多个角度理解问题，捕捉到更多潜在信息。</p>
<p>技术方面，单模态分析技术通常采用特定模态的专用技术，如NLP、CV、语音识别等；多模态分析技术需要开发跨模态的融合技术，包括特征对齐、特征融合、多模态深度学习（卷积神经网络（CNN）、循环神经网络（RNN））或Transformer等模型，在多个模态间建立关系。</p>
<h3>五、扩展</h3>
<h4>5.1 流程扩展</h4>
<p>多模态分析的一般流程如下：</p>
<p>数据获取与预处理、特征提取（将原始数据转化为易于分析的特征表示，如通过TF-IDF、词向量、BERT等模型提取文本的语义特征，使用卷积神经网络（CNN）提取图像的高层次特征）、模态对齐（不同模态的数据在时间、空间或语义上进行统一和同步）、特征融合（早期/中期/晚期）、模型训练与优化（融合后的特征用于训练机器学习或深度学习模型）、多模态信息的解读与分析（理解各模态对最终结果的贡献和影响）、验证与评估（准确率、精确率、召回率等指标，鲁棒性测试）。<sup><a href="#user-content-fn-1-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-1-2-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></p>
<h4>5.2 术语扩展</h4>
<p>查找资料时，出现频率比较高的词条为多模态情感分析、多模态语篇分析和多模态学习分析，不同领域的多模态分析虽然关注点不同，但都强调了多种数据模态在理解复杂现象中的重要性。</p>
<ol>
<li>
<p>多模态情感分析</p>
<p>多模态情感分析（Multimodal Sentiment Analysis）是通过结合多种模态数据（如语音、面部表情、肢体语言、文本等）来识别、理解和分析情感状态的技术。传统情感分析通常只依赖于单一模态（如文本分析），而多模态情感分析能够利用更丰富的感知信息，从不同的模态中提取情感特征，得出更全面的情感判断。<sup><a href="#user-content-fn-4-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-4-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup></p>
<ul>
<li>社交媒体分析：通过结合用户发布的文本、视频、语音等内容，来判断用户情感和态度。</li>
<li>人机交互：通过实时监测用户的语音语调、表情变化、身体动作等，优化人机对话系统的反应，提升用户体验。</li>
</ul>
</li>
<li>
<p>多模态语篇分析</p>
<p>多模态语篇分析（Multimodal Discourse Analysis）是一种将语言与其他模态（如图像、声音、视频、手势等）结合起来研究语篇（discourse）结构和意义的分析方法。它不仅关注文本，还包括所有参与信息传递的模态。该分析帮助理解不同模态在语篇中的角色和相互作用。</p>
<ul>
<li>新闻媒体分析：通过分析新闻中的文字、图片、视频等，研究不同模态如何共同传达信息和影响读者的理解。</li>
<li>广告：通过整合视觉设计、标语和背景音乐等，分析广告中不同模态如何影响观众的感知和购买行为。<sup><a href="#user-content-fn-5-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-5-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup></li>
</ul>
</li>
<li>
<p>多模态学习分析</p>
<p>多模态学习分析（Multimodal Learning Analytics, MLA）是一种将学习者的多模态数据（如文本作业、口头回答、视频演讲、眼动追踪、行为数据等）进行整合和分析的研究方法。它旨在通过这些不同模态的数据了解学习者的学习过程、行为模式和学习效果。</p>
<ul>
<li>个性化学习：通过分析学习者的眼动轨迹、面部表情、答题情况等，个性化推荐学习资源或调整教学内容。</li>
<li>课堂观察：通过记录学生的肢体语言、互动行为、语音等，分析课堂中的学习状态和参与度。</li>
<li>在线教育平台：结合视频、文本讨论、互动行为，分析学生的学习进度和理解情况，提升在线教育质量。<sup><a href="#user-content-fn-6-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-6-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup></li>
</ul>
</li>
</ol>
<h4>5.3 传媒领域扩展</h4>
<p>传媒领域的数据形式多样，包含文本（如新闻报道、社交媒体帖子）、图像（如图片广告）、音频（如播客）、视频（如新闻视频、直播内容）等。这些数据往往是孤立处理的，但多模态分析强调了将这些不同形式的数据进行整合的重要性，通过融合来自多个渠道的信息，可以更全面地理解受众的反应、内容的传播效果等。</p>
<ol>
<li>
<p>新闻视频多模态分析</p>
<p>一则新闻报道，既有记者的现场讲解（语音模态）、视频素材（图像模态），还有字幕和文字说明（文本模态）。通过对这些模态的综合分析，可以评估观众的关注点（视频中视觉吸引力的部分）、情感反应（语音语调的情感分析）以及新闻传播的效果（根据观看量和读者反馈）。这种多模态分析可以帮助新闻媒体优化新闻报道的形式，提高观众的参与度。<sup><a href="#user-content-fn-7-e14f8323244e517c69dabcd76b6c632a" id="user-content-fnref-7-e14f8323244e517c69dabcd76b6c632a" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup></p>
</li>
<li>
<p>社交舆情监控</p>
<p>从不同媒体渠道收集多种模态的数据，如新闻报道、社交媒体帖子的文字、用户评论中的情感、配图等，并分析它们之间的关联。在重大公共事件后，传媒机构可通过多模态分析收集新闻报道、社交媒体上的图文信息、相关视频和语音采访等数据，了解公众对事件的反应和态度。这些数据通过情感分析、文本关联分析、视频情绪分析等手段进行处理，帮助传媒机构实时掌握舆论动向，并迅速调整报道策略。</p>
</li>
<li>
<p>虚拟主播多模态分析</p>
<p>虚拟主播是一种结合视频、音频和文本的多模态媒体形式，广泛应用于网络直播、短视频和在线互动场景。在一场虚拟主播的直播中，通过多模态分析，直播平台可以评估观众对主播内容的反应，结合观众的弹幕、表情符号（文本）、点赞数（交互数据）、观看时长等，调整虚拟主播的语言风格（语音模态）、视频内容（图像模态）和直播节奏，从而优化直播体验并增加用户黏性。</p>
</li>
</ol>
<h3>六、总结</h3>
<p>单模态分析通常适合较为简单、专一的任务，具有成本低、实现简单的优势，但在处理复杂情境时会显得局限，信息获取不够全面。而多模态分析能够融合多种数据来源，提供更加全面、准确的分析结果，适合自动驾驶、医学诊断、情感计算等复杂应用场景。学习多模态分析（尤其在传媒领域）时可注意以下几点。</p>
<ol>
<li>
<p>不同的模态需要专门的技术来进行分析，掌握基础的单模态分析工具（如文本处理工具、图像处理工具等）后，应进一步学习如何通过跨模态技术进行融合，尤其是在应用深度学习模型时，理解如何通过共享特征或对齐特征进行模态之间的协同分析。实现跨模态的信息融合和分析。</p>
</li>
<li>
<p>多模态分析在个性化内容推荐和广告优化中具有强大的应用潜力，不同观众在观看视频时可能对文本、图像和语音模态有不同的反应，可通过多模态分析评估每个模态对观众兴趣和情感反应的贡献，从而进行精准的内容推荐或广告推送。</p>
</li>
<li>
<p>多模态情感分析为传媒领域中的舆情监控和人机交互提供了新的可能，通过将语音、文本、表情、肢体语言等多模态数据结合起来，可以更准确地理解受众的情感变化。这在社交媒体分析、新闻评论分析以及广告受众情感反应的分析中，都是非常重要的工具。</p>
</li>
</ol>
<h3>七、参考文章</h3>
<section data-footnotes="" class="footnotes"><h2 id="footnote-label" class="sr-only">Footnotes</h2>
<ol>
<li id="user-content-fn-1-e14f8323244e517c69dabcd76b6c632a">
<p>[<a href="https://www.researchgate.net/profile/Xiong-Lin-Luo/publication/343558825_duomotaishenduxuexizongshujisuanjiyingyongyanjiu/links/5f31cd53299bf13404b71469/duomotaishenduxuexizongshujisuanjiyingyongyanjiu.pdf">Google学术搜索_多模态深度学习综述</a>](<a href="https://www.researchgate.net/profile/Xiong-Lin-Luo/publication/343558825_duomotaishenduxuexizongshujisuanjiyingyongyanjiu/links/5f31cd53299bf13404b71469/duomotaishenduxuexizongshujisuanjiyingyongyanjiu.pdf">https://www.researchgate.net/profile/Xiong-Lin-Luo/publication/343558825_duomotaishenduxuexizongshujisuanjiyingyongyanjiu/links/5f31cd53299bf13404b71469/duomotaishenduxuexizongshujisuanjiyingyongyanjiu.pdf</a>) <a href="#user-content-fnref-1-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a> <a href="#user-content-fnref-1-2-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 1-2" class="data-footnote-backref">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-2-e14f8323244e517c69dabcd76b6c632a">
<p>[<a href="https://html.rhhz.net/tis/html/202002010.htm">面向自动驾驶目标检测的深度多模态融合技术</a>](<a href="https://html.rhhz.net/tis/html/202002010.htm">https://html.rhhz.net/tis/html/202002010.htm</a>) <a href="#user-content-fnref-2-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-3-e14f8323244e517c69dabcd76b6c632a">
<p>[<a href="http://www.wipm.cas.cn/kxcb/kpwz/201510/t20151029_4449884.html">CT、MRI、PET三种检查的临床比较</a>](<a href="http://www.wipm.cas.cn/kxcb/kpwz/201510/t20151029_4449884.html">http://www.wipm.cas.cn/kxcb/kpwz/201510/t20151029_4449884.html</a>) <a href="#user-content-fnref-3-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-4-e14f8323244e517c69dabcd76b6c632a">
<p>[<a href="https://bhxb.buaa.edu.cn/bhzk/cn/article/doi/10.13700/j.bh.1001-5965.2020.0451?viewType=HTML">基于语义相关的多模态社交情感分析</a>](<a href="https://bhxb.buaa.edu.cn/bhzk/cn/article/doi/10.13700/j.bh.1001-5965.2020.0451?viewType=HTML">https://bhxb.buaa.edu.cn/bhzk/cn/article/doi/10.13700/j.bh.1001-5965.2020.0451?viewType=HTML</a>) <a href="#user-content-fnref-4-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-5-e14f8323244e517c69dabcd76b6c632a">
<p>[<a href="https://d1wqtxts1xzle7.cloudfront.net/33129471/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AF%AD%E7%AF%87%E5%88%86%E6%9E%90%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD%E8%AF%AD%E8%A8%80%E5%AD%A6.pdf?1393913608=&amp;response-content-disposition=inline%3B+filename%3D2009_OE_30_4_F_o_re_ign_L_an_guage_E_du.pdf&amp;Expires=1726881025&amp;Signature=arZLRkheELTZYcsKyldep47mIuHroDrjrN6l0aTRmbHdbePmIEyCqX4BV3sv8Zyyv-kkl9y5w0R-HGYTIDWuoYETF2b2zUMB56ylcFMcm6GhmArbK0DahMcj48wgibGcuR6NfEoWdbA3lrqOXrJNydEgpidVQWwvFvoat01kljhF6I6p8k1ol4D0uQEgHlvmlJuTLbrjJN6m01MUltP6-Sfc6Aczj8RtlxnXw4MUgaHoWBZJInChdJG2UrNXINU8JIL1q0A1xj4Q89GKJ17qKoMtnZCRDpFBZ6Y6lyaCx5FTiu0VmHkKzA8nIC69MmOuvuDLIKxGF9ddLdeTHF8ADQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">多模态语篇分析与系统功能语言学</a>](<a href="https://d1wqtxts1xzle7.cloudfront.net/33129471/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AF%AD%E7%AF%87%E5%88%86%E6%9E%90%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD%E8%AF%AD%E8%A8%80%E5%AD%A6.pdf?1393913608=&amp;response-content-disposition=inline%3B+filename%3D2009_OE_30_4_F_o_re_ign_L_an_guage_E_du.pdf&amp;Expires=1726881025&amp;Signature=arZLRkheELTZYcsKyldep47mIuHroDrjrN6l0aTRmbHdbePmIEyCqX4BV3sv8Zyyv-kkl9y5w0R-HGYTIDWuoYETF2b2zUMB56ylcFMcm6GhmArbK0DahMcj48wgibGcuR6NfEoWdbA3lrqOXrJNydEgpidVQWwvFvoat01kljhF6I6p8k1ol4D0uQEgHlvmlJuTLbrjJN6m01MUltP6-Sfc6Aczj8RtlxnXw4MUgaHoWBZJInChdJG2UrNXINU8JIL1q0A1xj4Q89GKJ17qKoMtnZCRDpFBZ6Y6lyaCx5FTiu0VmHkKzA8nIC69MmOuvuDLIKxGF9ddLdeTHF8ADQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">https://d1wqtxts1xzle7.cloudfront.net/33129471/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AF%AD%E7%AF%87%E5%88%86%E6%9E%90%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD%E8%AF%AD%E8%A8%80%E5%AD%A6.pdf?1393913608=&amp;response-content-disposition=inline%3B+filename%3D2009_OE_30_4_F_o_re_ign_L_an_guage_E_du.pdf&amp;Expires=1726881025&amp;Signature=arZLRkheELTZYcsKyldep47mIuHroDrjrN6l0aTRmbHdbePmIEyCqX4BV3sv8Zyyv-kkl9y5w0R-HGYTIDWuoYETF2b2zUMB56ylcFMcm6GhmArbK0DahMcj48wgibGcuR6NfEoWdbA3lrqOXrJNydEgpidVQWwvFvoat01kljhF6I6p8k1ol4D0uQEgHlvmlJuTLbrjJN6m01MUltP6-Sfc6Aczj8RtlxnXw4MUgaHoWBZJInChdJG2UrNXINU8JIL1q0A1xj4Q89GKJ17qKoMtnZCRDpFBZ6Y6lyaCx5FTiu0VmHkKzA8nIC69MmOuvuDLIKxGF9ddLdeTHF8ADQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA</a>) <a href="#user-content-fnref-5-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-6-e14f8323244e517c69dabcd76b6c632a">
<p>[<a href="https://aver.nwnu.edu.cn/upload/formalarticle/202005/2020051859-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0%E5%88%86%E6%9E%90%EF%BC%9A%E5%AD%A6%E4%B9%A0%E5%88%86%E6%9E%90%E7%A0%94%E7%A9%B6%E6%96%B0%E7%94%9F%E9%95%BF%E7%82%B9.pdf">多模态学习分析：学习分析研究新生长点</a>](<a href="https://aver.nwnu.edu.cn/upload/formalarticle/202005/2020051859-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0%E5%88%86%E6%9E%90%EF%BC%9A%E5%AD%A6%E4%B9%A0%E5%88%86%E6%9E%90%E7%A0%94%E7%A9%B6%E6%96%B0%E7%94%9F%E9%95%BF%E7%82%B9.pdf">https://aver.nwnu.edu.cn/upload/formalarticle/202005/2020051859-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0%E5%88%86%E6%9E%90%EF%BC%9A%E5%AD%A6%E4%B9%A0%E5%88%86%E6%9E%90%E7%A0%94%E7%A9%B6%E6%96%B0%E7%94%9F%E9%95%BF%E7%82%B9.pdf</a>) <a href="#user-content-fnref-6-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 6" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-7-e14f8323244e517c69dabcd76b6c632a">
<p>[<a href="https://www.hanspub.org/journal/PaperInformation?paperID=61727">衡量视觉信息的多模态情感分析综述</a>](<a href="https://www.hanspub.org/journal/PaperInformation?paperID=61727">https://www.hanspub.org/journal/PaperInformation?paperID=61727</a>) <a href="#user-content-fnref-7-e14f8323244e517c69dabcd76b6c632a" data-footnote-backref="" aria-label="Back to reference 7" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section></div>
<div style="font-size:small;margin-top:8px;float:right;">转载请注明出处</div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://aneverspring.github.io/evenstar/">Even Star</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("08/09/2024"!=""){
    var startSite=new Date("08/09/2024");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);






</script>
<script src='https://blog.meekdai.com/Gmeek/plugins/GmeekTOC.js'></script>

</html>

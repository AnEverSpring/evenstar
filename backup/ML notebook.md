# 机器学习

## 基础知识

**机器学习（Machine learning）是人工智能的子集，是实现人工智能的一种途径，但并不是唯一的途径**。它是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能的学科。大概在上世纪80年代开始蓬勃发展，诞生了一大批数学统计相关的机器学习模型。

**深度学习（Deep learning）是机器学习的子集，灵感来自人脑，由人工神经网络（ANN）组成，它模仿人脑中存在的相似结构**。在深度学习中，学习是通过相互关联的「神经元」的一个深层的、多层的「网络」来进行的。「深度」一词通常指的是神经网络中隐藏层的数量。大概在2012年以后爆炸式增长，广泛应用在很多的场景中。

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 144539.png)

经验E，任务T，绩效测量P

如果它在T上的表现，由P测量，随经验E而改善

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 144835.png)

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 145038.png)

- **分类**：应用以分类数据进行模型训练，根据模型对新样本进行精准分类与预测。
- **聚类**：从海量数据中识别数据的相似性与差异性，并按照最大共同点聚合为多个类别。
- **异常检测**：对数据点的分布规律进行分析，识别与正常数据及差异较大的离群点。
- **回归**：根据对已知属性值数据的训练，为模型寻找最佳拟合参数，基于模型预测新样本的输出值。

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 145247.png)

- **数据预处理**：输入（未处理的数据 + 标签）→处理过程（特征处理+幅度缩放、特征选择、维度约减、采样）→输出（测试集 + 训练集）。
- **模型学习**：模型选择、交叉验证、结果评估、超参选择。
- **模型评估**：了解模型对于数据集测试的得分。
- **新样本预测**：预测测试集。

#### 机器学习基本名词

- **监督学习**（**Supervised Learning**）：训练集有标记信息，学习方式有分类和回归。
- **无监督学习**（**Unsupervised Learning**）：训练集没有标记信息，学习方式有聚类和降维。
- **强化学习**（**Reinforcement Learning**）：有延迟和稀疏的反馈标签的学习方式。通过观察来学习做成如何的动作。每个动作都会对环境有所影响，学习对象根据观察到的周围环境的反馈来做出判断。



- **示例/样本**：上面一条数据集中的一条数据。
- **属性/特征**：「色泽」「根蒂」等。
- **属性空间/样本空间/输入空间X**：由全部属性张成的空间。
- **特征向量**：空间中每个点对应的一个坐标向量。
- **标记**：关于示例结果的信息，如（（色泽=青绿，根蒂=蜷缩，敲声=浊响），好瓜），其中「好瓜」称为标记。
- **分类**：若要预测的是离散值，如「好瓜」，「坏瓜」，此类学习任务称为分类。
- **假设**：学得模型对应了关于数据的某种潜在规律。
- **真相**：潜在规律自身。
- **学习过程**：是为了找出或逼近真相。
- **泛化能力**：学得模型适用于新样本的能力。一般来说，训练样本越大，越有可能通过学习来获得具有强泛化能力的模型。

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 145721.png)

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 151322.png)

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 152431.png)

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 152539.png)

**如何防止过拟合呢**？一般的方法有Early Stopping、数据集扩增（Data Augmentation）、正则化、Dropout等。

- **正则化**：指的是在目标函数后面添加一个正则化项，一般有L1正则化与L2正则化。L1正则是基于L1范数，即在目标函数后面加上参数的L1范数和项，即参数绝对值和与参数的积项。
- **数据集扩增**：即需要得到更多的符合要求的数据，即和已有的数据是独立同分布的，或者近似独立同分布的。一般方法有：从数据源头采集更多数据、复制原有数据并加上随机噪声、重采样、根据当前数据集估计数据分布参数，使用该分布产生更多数据等。
- **DropOut**：通过修改神经网络本身结构来实现的。

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 152648.png)

- **平均绝对误差**（**Mean Absolute Error，MAE**），又叫平均绝对离差，是所有标签值与回归模型预测值的偏差的绝对值的平均。
- **平均绝对百分误差**（**Mean Absolute Percentage Error，MAPE**）是对MAE的一种改进，考虑了绝对误差相对真实值的比例。
- **均方误差**（**Mean Square Error，MSE**）相对于平均绝对误差而言，均方误差求的是所有标签值与回归模型预测值的偏差的平方的平均。
- **均方根误差**（**Root-Mean-Square Error，RMSE**），也称标准误差，是在均方误差的基础上进行开方运算。RMSE会被用来衡量观测值同真值之间的偏差。
- **R平方，决定系数**，反映因变量的全部变异能通过目前的回归模型被模型中的自变量解释的比例。比例越接近于1，表示当前的回归模型对数据的解释越好，越能精确描述数据的真实分布。

![](D:\Desktop\markdowm\建模.img\屏幕截图 2024-03-17 152800.png)

#### 如何选择最优的模型

（1）验证集评估选择

- 切分数据为训练集和验证集。
- 对于准备好的候选超参数，在训练集上进行模型，在验证集上评估。

（2）网格搜索/随机搜索交叉验证

- 通过网格搜索/随机搜索产出候选的超参数组。
- 对参数组的每一组超参数，使用交叉验证评估效果。
- 选出效果最好的超参数。

（3）贝叶斯优化

- 基于贝叶斯优化的超参数调优。

### 应用流程

1. 问题抽象与理解

   - 数据集是哪种类型？数值型，类别型还是图像？
   - 模型的最终目标是什么？
   - 如何定义和衡量“准确率”呢？
   - 以目前自身的机器学习知识来看，哪些算法在处理这类问题上效果很好？

2. 数据准备与处理

   - 特征提取是应用某种算法通过某种方式来量化数据的过程。比如，对于图像数据，我们可以采用计算直方图的方法来统计图像中像素强度的分布，通过这种方式，我们就得到描述图像颜色的特征。

     特征工程是将原始输入数据转换成一个更好描述潜在问题的特征表示的过程。

3. 多模型应用

	- 线性模型(逻辑回归、线性SVM)
	- 非线性模型(RBF、SVM、梯度下降分类器)

- 树和基于集成的模型(决策树、随机森林)
- 神经网络(多层感知机、卷积神经网络)



对于**模型选择**，当然很多需要依据实验效果来定，但我们也有一些先序的经验，比如：

- 对于稠密型多特征的数据集，随机森林算法的效果很不错；
- 逻辑回归算法可以很好处理高维度的稀疏数据；
- 对于图像数据，CNNs的效果非常好。